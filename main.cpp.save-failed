#include <iostream>
#include <fstream>
#include <vector>
#include <cmath>
#include <random>
#include <ctime>
#include <cassert>
#pragma GCC optimize("Ofast")

using namespace std;

mt19937_64 gen(time(0));
uniform_real_distribution <double> rng(0, 1);

namespace tools {
  vector <double> createRandomArray(int length) {
    vector <double> v;

    for(int i = 0; i < length; i++)
      v.push_back(rng(gen));

    return v;
  }
}

class Layer {
public:
  Layer(int numNeurons, int prevNumNeurons) {
    size = numNeurons;
    bias = tools::createRandomArray(numNeurons);
    output.resize(numNeurons);
    error.resize(numNeurons);
    outputDerivative.resize(numNeurons);
    weights.resize(numNeurons);

    if(prevNumNeurons) {
      for(int i = 0; i < numNeurons; i++)
        weights[i] = tools::createRandomArray(prevNumNeurons);
    }
  }

  int size;
  vector <double> bias, output, error, outputDerivative;
  vector <vector <double>> weights;
};

class Network {
public:

  Network(vector <int> &topology) {

    netSize = (int)topology.size();

    for(int i = 0; i < (int)topology.size(); i++) {
      layers.push_back(Layer(topology[i], (i > 0 ? topology[i - 1] : 0)));
    }
  }

  double activationFunction(double x) {
    return 1.0 / (1.0 + exp(-x));
  }

  vector <double> calc(vector <double> &input) { /// feed forward
    layers[0].output = input;

    for(int l = 1; l < netSize; l++) {
      for(int n = 0; n < layers[l].size; n++) {
        double sum = layers[l].bias[n];

        for(int prevN = 0; prevN < layers[l - 1].size; prevN++) {
          sum += layers[l - 1].output[prevN] * layers[l].weights[n][prevN];
        }

        layers[l].output[n] = activationFunction(sum);
        layers[l].outputDerivative[n] = layers[l].output[n] * (1 - layers[l].output[n]);
      }
    }

    return layers.back().output;
  }

  void backProp(vector <double> &target) {
    /// for output neurons
    for(int n = 0; n < layers.back().size; n++) {
      layers.back().error[n] = (layers.back().output[n] - target[n]) * layers.back().outputDerivative[n];
    }

    /// for hidden layers
    for(int l = netSize - 2; l > 0; l--) {
      for(int n = 0; n < layers[l].size; n++) {
        double sum = 0;
        for(int nextN = 0; nextN < layers[l + 1].size; nextN++)
          sum += layers[l + 1].weights[nextN][n] * layers[l + 1].error[nextN];

        layers[l].error[n] = sum * layers[l].outputDerivative[n];
      }
    }
  }

  void updateWeights(double LR) {
    for(int l = 1; l < netSize; l++) {
      for(int n = 0; n < layers[l].size; n++) {
        for(int prevN = 0; prevN < layers[l - 1].size; prevN++) {
          double delta = -LR * layers[l - 1].output[prevN] * layers[l].error[n];
          //cout << layers[l - 1].output[prevN] << " " << layers[l].error[n] << " " << LR << " " << delta << "\n";
          layers[l].weights[n][prevN] += delta;
        }

        /// update bias
        /// no more layers[l - 1].output[prevN], because bias isn't connected to previous neurons
        double delta = -LR * layers[l].error[n];

        layers[l].bias[n] += delta;
      }
    }
  }

  void train(vector <double> &input, vector <double> &target, double LR) {
    if((int)input.size() != layers[0].size) {
      cout << "Wrong input size!\n";
      assert(0);
    }

    if((int)target.size() != layers.back().size) {
      cout << "Wrong output size!\n";
      assert(0);
    }

    calc(input);
    backProp(target);
    updateWeights(LR);
  }

  int netSize;
  vector <Layer> layers;
};

namespace Training {
  const int inputSize = 1;
  const int outputSize = 1;

  void createDataset(int size, string path) {
    ofstream out (path);

    for(int i = 0; i < size; i++) {
      vector <double> inp, outp;
      for(int j = 0; j < inputSize; j++) {
        double x = rand() % 10;
        inp.push_back(x);
        out << x << " ";
      }
      for(int j = 0; j < outputSize; j++) {
        double x = int(inp[0]) % 2;
        outp.push_back(x);
        out << x << " ";
      }
      out << "\n";
    }
  }

  void readDataset(vector <vector <double>> &input, vector <vector <double>> &output, int size, string path) {
    ifstream in (path);
    double x;

    for(int i = 0; i < size; i++) {
      vector <double> inp, outp;
      for(int j = 0; j < inputSize; j++) {
        in >> x;
        inp.push_back(x);
      }

      for(int j = 0; j < outputSize; j++) {
        in >> x;
        outp.push_back(x);
      }

      input.push_back(inp);
      output.push_back(outp);
    }
  }
}

void parityFinder() {
  vector <int> topology;

  topology.push_back(1);
  topology.push_back(10);
  topology.push_back(1);

  Network NN(topology);

  bool create = true;

  int dataSize = 100000;

  if(create) {
    Training::createDataset(dataSize, "training.txt");
    return;
  }

  double split = 0.1;
  int trainSize = dataSize * split;
  vector <vector <double>> input, output;

  Training::readDataset(input, output, dataSize, "training.txt");

  for(int i = 0; i < trainSize; i++) {
    NN.train(input[i], output[i], 0.1);
  }

  double error = 0;

  for(int i = trainSize; i < dataSize; i++) {
    vector <double> ans = NN.calc(input[i]);

    double delta = (ans[0] - output[i][0]);
    error += delta * delta;

    if(i % 100 == 0) {
      cout << "Index : " << i << "\n";
      cout << "Input : " << input[0] << "\n";
      cout << "Output: " << output[i][0] << "\n";
      cout << "Got   : " << ans[0] << "\n";
    }
  }

  cout << "Total error: " << error << "\n";
}

int main() {
  vector <int> topology;

  /*topology.push_back(4);
  topology.push_back(1);
  topology.push_back(3);
  topology.push_back(4);

  Network NN(topology);

  vector <double> input, input2, target, target2;

  input.push_back(0.2);
  input.push_back(0.9);
  input.push_back(0.4);
  input.push_back(0.3);

  input2.push_back(0.3);
  input2.push_back(0.3);
  input2.push_back(0.3);
  input2.push_back(0.3);

  target.push_back(0);
  target.push_back(1);
  target.push_back(0);
  target.push_back(0);

  target2.push_back(0);
  target2.push_back(1);
  target2.push_back(1);
  target2.push_back(1);

  for(int epoch = 0; epoch < 100000; epoch++) {
    if(epoch % 100 == 0)
      cout << "Epoch " << epoch << " / 100000\n";
    NN.train(input, target, 0.1);
    NN.train(input2, target2, 0.1);
  }*/

  vector <double> output = NN.calc(input);

  for(auto &i : output)
    cout << i << " ";

  cout << "\n";

  vector <double> output2 = NN.calc(input2);

  for(auto &i : output2)
    cout << i << " ";
  return 0;
}
